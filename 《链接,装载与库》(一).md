###0x0001 操作系统做什么
操作系统的一个功能是提供抽象的接口，另一个主要功能是管理硬件资源。  
cpu的资源是有限的，无论怎么使用，资源总是这么多。在预算有限的情况下，我们主要分CPU，存储器和I/O设备三方面挖掘它们的潜力。  

####1 不要让cpu打盹  
早期CPU资源昂贵，一个程序在读写磁盘时，CPU就休息了~。所以人们写了个监控程序，当某个程序不用cpu是，监控程序就把另一个需要CPU资源的程序启动。这被称为 ***多道程序***。  

不过缺点很明显，程序之间调度策略太粗糙。调度时程序之间不分轻重缓急，如果有些程序急需CPU完成一些任务，那么有可能会等很久才会轮到他运行。  

经过稍事改进，每个程序运行一段时间后都主动让出CPU给其他程序，使得每个程序都有机会运行一小段时间。比如点一下鼠标，处理一个简短的任务就能看到效果。这种模式称为 ***分时系统***  

不过缺点是假如一个程序很耗时，就会一直霸占cpu。比如一个while(1)循环，那么整个系统就停止了。  

低端pc还应付的去，但高端中大型机就不行了。随后大佬们开始研究新一代系统。就是我们目前的***多任务系统***  。操作系统接管所有硬件资源，本身运行在一个受硬件保护的级别。  程序以进程的方式运作，有自己独立地址空间，使得进程之间的地址空间相互隔离。  

CPU资源由操作系统分配，每个进程根据优先级得到CPU。如果某个进程运行时间太长，系统会暂停该进程把CPU资源1分配给其他等待运行的进程。这种方式称为 ***抢占式***  

###2.设备驱动  
操作系统作为硬件层上层的上层，它是对硬件的管理和抽象。在unix中，硬件设备的访问形式跟访问普通文件形式一样。程序员从硬件细节解放出来。繁琐的硬件细节全都交给操作系统的 ***硬件驱动*** 程序完成  
 
 
###3.内存不够了？  
早期计算机，程序直接运行在物理内存上，也就是说，程序运行时所访问的地址都是物理地址。如果一个计算几同时只运行一个程序，程序要求的内存空间不要超过物理内存大小，就不会有问题。但事实上为了更有效运行多个程序时，CPU利用率会比较高。那么 **如何将计算机上有限的物理内存分配给多个程序使用**  

假设我们有128M内存，A 10MB,B 100MB,C 20MB 。那么直接的做法是内存把A，B程序都装进来。这样就能同时运行A,B两程序了。但，问题是~ 

* **地址空间不隔离**  由于所有程序都是直接访问物理地址，恶意程序挥着bug都会影响其他程序。使它们崩溃，数据泄露。  
*  **内存使用效率低** 由于没有内存管理机制，通常需要一个程序执行时，监控程序吧整个程序装入内存后开始执行。如果我们需要程序C，我们用一个办法把其他程序写入磁盘，等到需要的时候再读回来。这里只能把A,B程序换出，再换如C。可以看到整个过程有大量的数据换入换出，效率低下。  
*  **程序运行地址不稳定**  因为每次把程序装入内存时，位置是不确定的。而程序编写时，访问的数据和指令跳转的目标地址很多是固定的。这涉及到程序 **重定位**问题。  为编写程序造成一定困难。  

解决思路是：加个中间层。一种间接的地址访问方法。想法是这样的，我们把程序给出的地址看做事一种虚拟地址，然后通过某种映射的方式，将这个虚拟地址转换成实际的物理地址。这样，我们能控制这个虚拟地址和物理地址的映射过程，就可以保证任意一个程序能够访问的内存区域跟另外一个程序互相不重叠，打到地址空间隔离的效果。  

####3.1关于隔离  
对于程序来说，他需要一个简单的运行环境，有单一的内存空间，自己的CPU，整个程序不需要关心其他的程序。地址空间分两种：物理地址和虚拟地址。物理地址是实实在在的内存。而虚拟地址是不存在的，是以程序的角度来看待的。每个进程都有自己独立的虚拟空间并且只能访问自己的空间，这样就有效的做到进程隔离。  

####3.2分段（Segmentation）和分页（Paging）  
分段:  
基本思路就是把一段与程序所需要的内存空间大些的虚拟空间映射到某个地址空间  
分段可以解决地址隔离问题。程序无需关系物理地址的变化，所以不再需要重定位。  
但没有解决内存使用效率的问题，内存不足时程序会被整段的换入换出，造成大量磁盘操作。根据程序的局部性原理，程序运行时的某个时间段内，只是用到一小部分数据。因此，人们想到用更小粒度内存分割和映射的方法来提高内存使用率。这种方法就是***分页***  

分页：   
基本方法就是把地址空间人为的分成固定大小的页，每一页大小由硬件决定，由操作系统决定页大小。如某个CPU支持4KB或4MB的页大小，那么系统可以选择其中一种。  
我们使用的PC机是32位的虚拟地址空间，也就是4GB，按4kb分页的话，共有1 048 576个页，物理空间也是同样的分法。  

那么，我们把进程的虚拟地址空间按页分割，把常用的数据和代码装载进内存，不常用的保存在磁盘里，当需要的时候再从磁盘里取出来即可。  

我们把虚拟空间的页叫 ***虚拟页***   物理内存的页叫 ***物理页***  磁盘里的页叫 ***磁盘页***  

如果进程需要的页不在内存中，当进程需要时会被硬件捕获，就是会出现***错误页*** 操作系统会接管进程，负责从磁盘取出需要的页装入内存，建立与进程的映射关系。  

虚拟内存需要硬件支持，不同CPU来说都不同。几乎所有硬件都采用一个叫 ***MMU(Memory Management Unit)***  来进行映射。  

| CPU | -- Virtual Address -- | MMU | -- Physical Address -- | Physical Memory |  

CPU 发出的是虚拟地址 即我们程序看到的是虚拟地址。经过转换后变成 物理地址  

####线程基础  
线程有时被称为 轻量级进程，是程序执行的最小单元。一个标准线程有线程ID，当前指令指针PC，寄存器集合和堆栈组成。  
一个进程由多个线程组成，各线程之间共享程序的内存空间及一些进程资源（如打开文件和信号）。  



####线程访问权限  
图

####线程调度与优先级  
线程状态：  
  
 * 运行 ：此时线程正在执行
 * 就绪 ：线程可以运行，但CPU已经被占用
 * 等待 ：此时线程正在等待某一事件发生，无法执行。  
 
线程调度目前基本都有***优先级调度***和***轮转法***  
轮转法： 各个线程轮流执行一小段时间。
优先级调度：系统决定线程按什么顺序轮流执行。  
在具有优先级调度的系统中，线程都拥有各自的线程优先级。高优先级会更早执行。
系统还会根据不同线程的表现自动调整优先级    
我们一般把频繁等待的线程称之为 ***IO密集型线程*** ，把很少等待的线程称之为 ***CPU密集型线程*** 。所有 IO密集型总是比CPU密集型更容易得到优先级的提升。  

在优先级的调度下，存在一种***饿死***的现象。 一个线程被饿死，是说他的优先级较低，在他执行之前总有高优先级的线程在执行。因此这个低优先级的始终无法执行，很可能会被饿死。  

为了避免饿死现象，系统调度会提升那些等待时间过长得不到执行的线程优先级。  

总结一下，线程优先级改变的三种方式。  

* 用户指定优先级  
* 根据进入等待状态的频繁程度提高或降低优先级。
* 长时间得不到执行而被提升优先级  

####线程安全  
#####锁

#####二元信号量   
是最简单的一种锁，只有两种状态：占用与非占用。第一个获取二元信号量的会获得锁，并置为占用状态，此后其他的所有试图获取该锁的都会等待，直到释放。  

对于允许多个线程并发访问的资源，多元信号量简称***信号量***。一个初始值为N的信号量允许N个并发访问。线程访问资源的时候首先获取信号量，进行如下操作：  

* 将信号量-1  
* 如果信号量值小于0，进入等待状态，否则继续执行。  
访问完资源后，线程释放信号量，进行如下操作：  
* 信号量+1  
* 如果信号量值小于1，唤醒一个等待中的线程。  

#####互斥量  
互斥量和二元信号很类似，资源仅同时允许一个线程访问，但不同的是，信号量在整个系统可以被任意线程获取并释放，也就是说，同一个信号量可以被一个线程获取之后被另一个线程释放。而互斥量则要求哪个线程获取互斥量，哪个线程释放这个锁。  

#####临界区  
比互斥量更加严格的同步手段。术语中，把临界区的锁的获取称为进入临界区，而把锁的释放称为离开临界区。  
临界区和互斥量与信号量的区别在于，互斥量和信号量在任何进程可见。临界区的作用仅限于本进程，其他进程无法获取该锁。  

#####读写锁   
针对于某些数据读取频繁，偶尔写入。上述的锁就会特别低效。为了避免此问题，读写锁有两种获取方式，***共享的*** 和 ***独占的***。当锁处于自由状态时，可以使用任何方式获取锁，并将锁置于对应状态。如果锁是共享状态，其他线程可以以共享状态获取锁，那么它必须等待锁被所有线程释放。处于独占状态的锁将阻止其他线程获取该锁。  

#####条件变量  
其作用类似于一个栅栏。使用条件变量可以让许多线程一起等待某个事件的发生，当事件发生是，所有的线程可以一起恢复执行。  
